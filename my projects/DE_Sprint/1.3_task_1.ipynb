{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc29a39",
   "metadata": {},
   "source": [
    "<h1> Подраздел 1.3 <span class=\"tocSkip\"></span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c1912d",
   "metadata": {},
   "source": [
    "<h2> Задание 1. Парсинг сайта hh.ru <span class=\"tocSkip\"></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3559641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req \n",
    "from bs4 import BeautifulSoup   \n",
    "import time\n",
    "import json\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f9de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим пустой словарь, куда будем записывать данные\n",
    "data = {\n",
    "\n",
    "        \"data\" : []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fe32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# напишем функцию, которая будет проходить по категориям опыта на сайте hh.ru,\n",
    "# потом по страницам выдачи от 1 до 120 и парсить необходимые данные\n",
    "\n",
    "def parsing():\n",
    "    \n",
    "    experience = { 'Нет опыта' : 'noExperience',\n",
    "                  'От 1 года до 3 лет' : 'between1And3',\n",
    "                  'От 3 до 6 лет' : 'between1And3',\n",
    "                  'Более 6 лет' : 'moreThan6'\n",
    "        \n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    headers = { \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,/;q=0.8\", \n",
    "               \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; rv:91.0) Gecko/20100101 Firefox/91.0\" }\n",
    "\n",
    "    for exp in range(len(experience)):\n",
    "        base_url = f\"https://spb.hh.ru/search/vacancy?experience={list(experience.values())[exp]}&text=python+разработчик&page=\"\n",
    "        \n",
    "        for page in range(120):\n",
    "        \n",
    "            url = base_url+f\"{page}\"\n",
    "\n",
    "            resp_text = req.get(url, headers=headers)\n",
    "\n",
    "\n",
    "            soup = BeautifulSoup(resp_text.text, \"lxml\") \n",
    "            #tags  = soup.find_all(class_=\"serp-item__title\", limit=None)\n",
    "            tags = soup.find_all(attrs = {\"data-qa\":\"serp-item__title\"}, limit=None) \n",
    "            #print(tags)\n",
    "            for tag in tqdm.tqdm(tags):\n",
    "                time.sleep(5)\n",
    "                resp_tag = req.get(tag.attrs['href'], headers=headers)\n",
    "                soup = BeautifulSoup(resp_tag.text, \"lxml\")\n",
    "\n",
    "                #tags_object = soup.find(attrs={})\n",
    "\n",
    "                #tag_experience = soup.find(attrs={\"data-qa\":\"vacancy-salary\"}).find(attrs = {\"data-qa\":\"vacancy-experience\"}).text\n",
    "\n",
    "                tag_experience = soup.find(attrs={\"data-qa\":\"vacancy-experience\"})\n",
    "                if tag_experience != None:\n",
    "                  #print('нашлась')\n",
    "                  tag_experience = soup.find(attrs={\"data-qa\":\"vacancy-experience\"}).text\n",
    "                tag_price = soup.find(attrs = {\"data-qa\":\"vacancy-serp__vacancy-compensation\"})\n",
    "                if tag_price != None:\n",
    "                  #print('нашлась')\n",
    "                  tag_price = soup.find(attrs={\"data-qa\":\"vacancy-serp__vacancy-compensation\"}).text\n",
    "                tag_location = soup.find(attrs = {\"data-qa\":\"vacancy-view-location\"})\n",
    "                if tag_location != None:\n",
    "                  #print('нашлась')\n",
    "                  tag_location =  soup.find(attrs = {\"data-qa\":\"vacancy-view-location\"}).text\n",
    "\n",
    "                print(tag.text, tag_experience, tag_price, tag_location)#, tag.attrs['href'])\n",
    "\n",
    "                data['data'].append({\"title\" : tag.text, \"work_experience\":tag_experience, \"salary\" : tag_price, \"region\" : tag_location} )\n",
    "\n",
    "                with open(\"data.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "                  json.dump(data,file, ensure_ascii = False)\n",
    "\n",
    "                #with open(data, 'w', encoding='utf-8') as file:\n",
    "                    #file.write(json.dumps(data, ensure_ascii=False, indent='\\t')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63be1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "parsing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d90d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
